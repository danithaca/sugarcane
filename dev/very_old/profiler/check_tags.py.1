import glob, re, os, csv

def removeDupes(L):
	L2 = []
	for l in L:
		if not l in L2: L2.append(l)
	return(L2)

def getClassAndIdTags( f ):
	#Find all class tags
	D = re.findall("class=[\"'](.+?)[\"']", file(f,'r').read())
	C = []
	for d in D: C += d.split(' ')

	#Find all id tags
	I = re.findall("id=[\"'](.*?)[\"']", file(f,'r').read())

	return(C,I)


##############################################################################

#F = glob.glob("/scratch/unmirrored5/agong/blog_panel_crawl/*/index.html")
F = glob.glob('/scratch/scratch2/agong/pol_blog_front_pages_10.20.2011/files/wave*/*')
print 'Total matches:', len(F)

#tags = ['post-outer','type-post','entry-header','asset-header', 'main_column', 'form-text']
tags = []

my_csv = csv.writer(file('tag_output.csv','w'))
my_csv.writerow( ['url'] + tags )

matched_pages = []
unmatched_pages = []
mmatched_pages = []

matched_tags = []
unmatched_tags = {}

print 'Testing known tags...'

count = 0
for f in F:
	if not os.path.isdir(f):
		count+=1
		(C,I) = getClassAndIdTags(f)

#		U = f.split('/')[-2]
		U = f.split('/')[-1]
		R = [int(t in C) for t in tags]
		my_csv.writerow( [U] + R )

		if sum(R) == 1:
			matched_pages.append( f )
			for t in removeDupes(C+I):
				if not t in matched_tags: matched_tags.append(t)

		if sum(R) > 1:
			print R, '\t', U
			mmatched_pages.append( f )

		if sum(R) == 0:
			unmatched_pages.append( f )
			for t in removeDupes(C+I):
				if not t in matched_tags:
					if t in unmatched_tags: unmatched_tags[t] +=1
					else: unmatched_tags[t] = 1

		if not count%100: print count

#raw_input('...')

##############################################################################

"""
print 'Finding matched tags...'
#Identify all tags that occur in any matched page
for f in matched_pages:
		(C,I) = getClassAndIdTags(f)
		for t in removeDupes(C+I):
			if not t in mtags: mtags.append(t)
#print len(mtags)

print 'Finding unmatched tags...'
#Find tags that do not occur in any matched pages
utags = {}
for f in unmatched_pages:
		(C,I) = getClassAndIdTags(f)
		for t in removeDupes(C+I):
			if not t in mtags:
				if t in utags: utags[t] +=1
				else: utags[t] = 1

#		U = f.split('/')[-2]
#		U = f.split('/')[-1]
#		print U
"""

for t in utags:
	if utags[t] > 10:
		print str(utags[t]) + '\t' + t


print "Matched pages:", len(matched_pages)
print "Unmatched pages:", len(unmatched_pages)
print "Multiple matched pages:", len(mmatched_pages)

#print '='*80
#print post_outer_count
#print type_post_count

#		index_count += 1
#		if 'post-outer' in C: post_outer_count+=1
#		if 'postMeta' in C: post_meta_count+=1
#		if 'type-post' in C: post_meta_count+=1

#index_count = 0
#post_outer_count = 0
#type_post_count = 0
